{"cells":[{"cell_type":"markdown","metadata":{"id":"pjQRTsJzHRLi"},"source":["# **Initial Load**\n","\n","Authenticate with Google Drive and read in our dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YiS_6Rv9HKaO","tags":[]},"outputs":[],"source":["# Install any required packages.\n","!pip install -U -q PyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2AVhMYIHdBa","tags":[]},"outputs":[],"source":["# Import any required libraries.\n","from google.colab import auth\n","from google.colab import drive\n","from patsy import dmatrices\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from oauth2client.client import GoogleCredentials\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, balanced_accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.preprocessing import scale\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQw1PkhYHW8B","tags":[]},"outputs":[],"source":["# Authenticate with Google Drive.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e33YZKsNHW97","tags":[]},"outputs":[],"source":["# Download our dataset from Google Drive.\n","downloaded_file = drive.CreateFile({ 'id': '14RMV7CRXwwCt_9iLHenyQrB9GC5gYwul' })\n","downloaded_file.GetContentFile('ChicagoCrimeRecords.csv')\n","chicago_crime_records = pd.read_csv('ChicagoCrimeRecords.csv')"]},{"cell_type":"code","source":["# Clear the downloaded file and any other related variables from memory, once we've converted it to a data frame.\n","del downloaded_file, drive, gauth"],"metadata":{"id":"UHIAauFBv-WW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Preparation**\n","Trim our dataset and split it out into training and test sets."],"metadata":{"id":"Vt98q9a6_fVk"}},{"cell_type":"code","source":["# Find any NANs.\n","chicago_crime_records.isnull().sum()"],"metadata":{"id":"vuTPit3yu7sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Determine the size of our dataset with the NANs removed.\n","len(chicago_crime_records.index) - chicago_crime_records.isnull().sum().sum()"],"metadata":{"id":"KTRfH1CoCt05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop any NANs.\n","chicago_crime_records.dropna(inplace = True)"],"metadata":{"id":"G9qRluck9yMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove any columns that we are confident will not be of any use to our model.\n","chicago_crime_records.drop(\n","    columns = [\n","        'Block',\n","        'Case Number',\n","        'Date',\n","        'Description',\n","        'ID',\n","        'Latitude',\n","        'Location',\n","        'Longitude',\n","        'Updated On',\n","        'X Coordinate',\n","        'Y Coordinate',\n","        'Year'],\n","    axis = 1,\n","    inplace = True,\n","    errors = 'ignore')"],"metadata":{"id":"KPYlQ2AF_oht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encode the 'Arrest', 'Domestic', 'FBI Code', 'IUCR' and 'Location Description' columns.\n","chicago_crime_records['Arrest'] = chicago_crime_records['Arrest'].astype(int)\n","\n","chicago_crime_records['Domestic'] = chicago_crime_records['Domestic'].astype(int)\n","\n","chicago_crime_records['FBI Code'] = chicago_crime_records['FBI Code'].astype('category')\n","chicago_crime_records['FBI Code'] = chicago_crime_records['FBI Code'].cat.codes\n","\n","chicago_crime_records['IUCR'] = chicago_crime_records['IUCR'].astype('category')\n","chicago_crime_records['IUCR'] = chicago_crime_records['IUCR'].cat.codes\n","\n","chicago_crime_records['Location Description'] = chicago_crime_records['Location Description'].astype('category')\n","chicago_crime_records['Location Description'] = chicago_crime_records['Location Description'].cat.codes"],"metadata":{"id":"rAzSeiZA_wcN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a look at our dataset, once we've encoded all of our features.\n","chicago_crime_records.head()"],"metadata":{"id":"NN34LQSOiVfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Separate out our indepedent and dependent variables.\n","X = chicago_crime_records.drop(columns = 'Primary Type')\n","Y = chicago_crime_records['Primary Type']"],"metadata":{"id":"HBe0XGt-_90r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a small sample of our dataset, to test out our imputation by KNN approach.\n","X_sample = X.sample(250000, random_state = 111)"],"metadata":{"id":"0chb8B3c69TU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find any NANs in our sampled dataset.\n","X_sample.isnull().sum()"],"metadata":{"id":"OM8BBjz68MHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Impute any NANs with KNN.\n","imputer = KNNImputer(n_neighbors = 5, weights = 'uniform', metric = 'nan_euclidean')\n","imputer.fit(X_sample)\n","X_sample_imputed = imputer.transform(X_sample)"],"metadata":{"id":"bmiFzVJD65oy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confirm that all missing values were removed.\n","print('Missing: %d' % sum(np.isnan(X_sample_imputed).flatten()))"],"metadata":{"id":"qIzfc2Mz9Tba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split out our data into training and test sets.\n","x_train, x_test, y_train, y_test = train_test_split(X_sample, Y.sample(250000), test_size = 0.2, random_state = 123)"],"metadata":{"id":"EDKjJ6Nt68Ew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split out our imputed data into training and test sets.\n","x_imputed_train, x_imputed_test, y_train, y_test = train_test_split(X_sample_imputed, Y.sample(250000), test_size = 0.2, random_state = 123)"],"metadata":{"id":"WaTUoCL7B5pI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale our training and test data.\n","x_train_scaled = scale(x_imputed_train)\n","x_test_scaled = scale(x_imputed_test)"],"metadata":{"id":"IrNc3F28RImO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a look at our scaled data.\n","x_train_scaled"],"metadata":{"id":"jXYEd25OaGnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clear the original data frame and other assorted variables from memory, now that we no longer need it.\n","del chicago_crime_records, X, Y"],"metadata":{"id":"dzB0SEqswZrW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model Tuning**\n","Carry out some parametric tuning before we train our Random Forest classifier."],"metadata":{"id":"rbqt6bNk4gCA"}},{"cell_type":"code","source":["# Carry out some hyperparameter tuning.\n","parameters = {\n","    'n_estimators': [25, 50, 75],\n","    'max_features': ['auto', 'sqrt', 'log2'],\n","    'max_depth': [5, 7, 9],\n","    'criterion': ['gini', 'entropy']\n","}\n","\n","tuned_model = GridSearchCV(RandomForestClassifier(), parameters).fit(x_train.sample(n = 50000), y_train.sample(n = 50000))"],"metadata":{"id":"9T9UUPdG4kAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take a look at the resultant parameters.\n","tuned_model.best_params_"],"metadata":{"id":"LdMaZDZZjvtM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model Training**\n","Train a Random Forest classifier."],"metadata":{"id":"3V5qzGsta6_-"}},{"cell_type":"code","source":["# Train a Random Forest classifier.\n","classifier = RandomForestClassifier(\n","    bootstrap = True,\n","    class_weight = None,\n","    criterion = 'entropy',\n","    max_depth = 7,\n","    max_leaf_nodes = None,\n","    min_impurity_decrease = 0.0,\n","    min_samples_leaf = 1,\n","    min_samples_split = 2,\n","    min_weight_fraction_leaf = 0.0,\n","    n_estimators = 50,\n","    n_jobs = 1,\n","    oob_score = False,\n","    random_state = 41,\n","    verbose = 0,\n","    warm_start = False)\n","\n","classifier.fit(x_train_scaled, y_train)\n","classifier_predictions = classifier.predict(x_test_scaled)"],"metadata":{"id":"lJr33WRFA7IB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model Evalution**\n","Evaluate our Random Forest classifier."],"metadata":{"id":"9uXm9zpUogDN"}},{"cell_type":"code","source":["# Evaluate the importance of the features in our model.\n","feature_importance = pd.Series(\n","    classifier.feature_importances_,\n","    index = x_train.columns).sort_values(ascending = False)\n","\n","feature_importance"],"metadata":{"id":"mb7WJhtcnJnu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the importance of the features in our model.\n","sns.barplot(x = feature_importance, y = feature_importance.index)\n","plt.xlabel('Feature Importance Score')\n","plt.ylabel('Features')\n","plt.title('Visualizing Important Features')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"RdmOcgSHoHKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display a confusion matrix for our model.\n","ConfusionMatrixDisplay(\n","    confusion_matrix = confusion_matrix(y_test, classifier_predictions),\n","    display_labels = classifier.classes_).plot()\n","\n","plt.show()"],"metadata":{"id":"ooFWHXJIddxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the accuracy, precision, and recall of our model.\n","print(\"Accuracy: \", accuracy_score(y_test, classifier_predictions))\n","print(\"Recall\", recall_score(y_test, classifier_predictions, average = 'macro'))\n","print(\"Precision\", precision_score(y_test, classifier_predictions, average = 'macro'))"],"metadata":{"id":"t5eTseOmbuvI"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/deborahdjon/CA683_Group_Project/blob/main/Workbooks/Chicago_Crime_Records_RandomForest.ipynb","timestamp":1676822753012}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}